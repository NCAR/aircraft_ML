{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc01067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0625d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pbp file\n",
    "dsH = xr.open_dataset('Data/20250524_022503_F2DS_H.pbp.nc',decode_times=False)\n",
    "dsV = xr.open_dataset('Data/20250524_022503_F2DS_V.pbp.nc',decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ea2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open temp etc file\n",
    "ds_env = xr.open_dataset('Data/RF02.20250524.004127_075522.PNI.nc',decode_times=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab693c5",
   "metadata": {},
   "source": [
    "### Saves probe time to UTC to display on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19fe624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(ds):\n",
    "    \"\"\"\n",
    "    Convert Time variable in pbp dataset to datetime64[ns] using FlightDate attribute.\n",
    "    \"\"\"\n",
    "    FlightDate = pd.to_datetime(ds.FlightDate)\n",
    "\n",
    "    origin = np.datetime64(FlightDate)\n",
    "    utc_times = origin + ds['probetime'].astype('timedelta64[s]')\n",
    "    return utc_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604a465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cutoffs(ds_env):\n",
    "    \"\"\"\n",
    "    Find the liquid and solid cutoffs based on ATX values in the environmental dataset.\n",
    "    Liquid cutoff: earliest time where ATX >= 1\n",
    "    Solid cutoff: earliest time where ATX <= -40\n",
    "    Returns:\n",
    "        liquid_cutoff (np.datetime64): Time of liquid cutoff\n",
    "        solid_cutoff (np.datetime64): Time of solid cutoff\n",
    "    \"\"\"\n",
    "    mask = (ds_env.ATX >=1)\n",
    "    # Find the earliest time where ATX >= 0\n",
    "    liquid_cutoff = ds_env.isel(Time =mask.values)['Time'].max().values\n",
    "\n",
    "    mask = (ds_env.ATX <= -40)\n",
    "    solid_cutoff = ds_env.isel(Time =mask.values)['Time'].min().values\n",
    "    print(f\"Liquid cutoff time: {liquid_cutoff}\")\n",
    "    print(f\"Solid cutoff time: {solid_cutoff}\")\n",
    "    return liquid_cutoff, solid_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b1d09",
   "metadata": {},
   "source": [
    "## Quality Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "632f4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "AREARATIO_MAX = 0.95\n",
    "ASPECTRATIO_MIN = 0.90\n",
    "ASPECTRATIO_TOL = 0.05\n",
    "ASPECTRATIO_LINE_MAX = 0.1\n",
    "VOID_THRESHOLD = 0.10 # Max allowable void fraction (e.g., 10%)\n",
    "DIODEGAPS_THRESH = 1\n",
    "SIZE_THRESH = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b025566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rect_mask(ds: xr.Dataset) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Generates a boolean mask to isolate long lines/perfect rectangle particles\n",
    "    from raw particle metadata in an xarray Dataset.\n",
    "\n",
    "    The filter uses two main criteria:\n",
    "    1. High Area Ratio (arearatio): Particle area relative to its bounding box.\n",
    "       A high value indicates a solid, well-defined shape (like a line or\n",
    "       rectangle), not a fragmented/wispy particle.\n",
    "    2. High Elongation: The ratio of the particle's longest dimension to its\n",
    "       shortest dimension is high, characterizing a long line.\n",
    "\n",
    "    Args:\n",
    "        ds: xarray Dataset containing particle metrics with dimensions for\n",
    "            'particle_id' and variables 'xsize', 'ysize', and 'arearatio'.\n",
    "\n",
    "    Returns:\n",
    "        xr.DataArray: A boolean mask (True for particles to keep).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Define Filtering Thresholds ---\n",
    "    # Threshold for arearatio (Area / Bounding Box Area).\n",
    "    # LINE: 0.09095, PARTICLE: 0.00615. Using 0.05 will isolate the LINE.\n",
    "    AREA_RATIO_THRESHOLD = 0.05 \n",
    "    \n",
    "    # Threshold for Elongation (max_size / min_size).\n",
    "    # LINE: 140/10 = 14. PARTICLE: 1160/70 ~ 16.5. \n",
    "    # We use this to ensure the particle is very long/thin.\n",
    "    ELONGATION_THRESHOLD = 5 \n",
    "\n",
    "    \n",
    "    # --- 2. Calculate Elongation Ratio ---\n",
    "    # Determine the maximum and minimum size dimensions for each particle\n",
    "    max_size = ds['xsize'].where(ds['xsize'] > ds['ysize'], other=ds['ysize'])\n",
    "    min_size = ds['ysize'].where(ds['xsize'] > ds['ysize'], other=ds['xsize'])\n",
    "    \n",
    "    # Calculate the elongation ratio\n",
    "    elongation_ratio = max_size / min_size\n",
    "    \n",
    "    # --- 3. Create Mask Components ---\n",
    "    \n",
    "    # Filter A: Particles must have a high arearatio (solid shape)\n",
    "    mask_solid = ds['arearatio'] > AREA_RATIO_THRESHOLD\n",
    "    \n",
    "    # Filter B: Particles must be highly elongated (long line/rectangle)\n",
    "    mask_elongated = elongation_ratio > ELONGATION_THRESHOLD\n",
    "    edge_mask = ds['edgetouch'] == 0\n",
    "    \n",
    "    # --- 4. Combine Masks ---\n",
    "    # The final mask requires both conditions to be True:\n",
    "    # High Area Ratio AND High Elongation\n",
    "    final_mask = mask_solid & mask_elongated & edge_mask\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46c171b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exclusion_mask(ds,\n",
    "                        arearatio_max=AREARATIO_MAX,\n",
    "                        aspectratio_min=ASPECTRATIO_MIN,\n",
    "                        aspectratio_line_max=ASPECTRATIO_LINE_MAX,\n",
    "                        void_threshold=VOID_THRESHOLD,\n",
    "                        size_threshold=100,\n",
    "                        diodegaps_thresh=1):\n",
    "    \"\"\"\n",
    "    Build a boolean exclusion mask (True = exclude) for particles in `ds`.\n",
    "    Returns an xarray.DataArray aligned with ds['Time'].\n",
    "    \"\"\"##\n",
    "    # Donut / hollow / out-of-focus\n",
    "    donut_mask = (ds['diodegaps'] > diodegaps_thresh)\n",
    "\n",
    "    # Near-perfect rectangles / squares\n",
    "    #square_mask = (ds['arearatiofilled'] > arearatio_max) & (ds['aspectratio'] > aspectratio_min)\n",
    "\n",
    "    \n",
    "    ## wider lines\n",
    "    rect_mask = generate_rect_mask(ds)\n",
    "\n",
    "    line_mask = (ds['aspectratio'] < aspectratio_line_max) & (ds['edgetouch'] == 0)\n",
    "\n",
    "    # Calculate the Void Index (Area of the Void / Total Filled Area)\n",
    "    void_index = (ds['areafilled'] - ds['area']) / ds['areafilled']\n",
    "\n",
    "    # Create a mask to REJECT particles with a high void index\n",
    "    # We use >= to ensure the filter works correctly\n",
    "    void_mask = void_index >= void_threshold\n",
    "    \n",
    "\n",
    "    # Small particles (size cutoff)\n",
    "    size_mask = ds['diam'] <= size_threshold\n",
    "\n",
    "    exclusion_mask = size_mask | donut_mask | rect_mask | line_mask |void_mask\n",
    "    return exclusion_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "543ddcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(ds):\n",
    "    # keep conditions\n",
    "    size_ok = ds['diam'] >= SIZE_THRESH\n",
    "    aspect_ok = ds['aspectratio'] > ASPECTRATIO_TOL\n",
    "\n",
    "    # exclude donuts: diodegaps > threshold => NOT keep\n",
    "    not_donut = ds['diodegaps'] <= DIODEGAPS_THRESH\n",
    "\n",
    "    # exclude near-perfect filled squares/rectangles:\n",
    "    # prefer 'arearatiofilled' if present, else fall back to 'arearatio'\n",
    "    areafill = ds.get('arearatiofilled', ds.get('arearatio', None))\n",
    "    if areafill is None:\n",
    "        # if neither exists, conservatively don't exclude on fill\n",
    "        not_square = True\n",
    "    else:\n",
    "        square_exclude = (areafill >= AREARATIO_MAX) & (np.abs(ds['aspectratio'] - 1) <= ASPECTRATIO_TOL)\n",
    "        not_square = ~square_exclude\n",
    "\n",
    "    # final keep mask: size AND aspect AND not donut AND not square\n",
    "    keep = size_ok & aspect_ok & not_donut & not_square\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddcc3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all exclusion masks using OR\n",
    "def filter_particles(ds,ds_env, start_index=0):\n",
    "    l_mask, s_mask = find_cutoffs(ds_env)\n",
    "    mask = create_mask(ds)\n",
    "\n",
    "    # --- Apply the mask ---\n",
    "    ds_filt = ds.isel(Time=mask)\n",
    "    rect_mask = generate_rect_mask(ds_filt)\n",
    "    ds_filt = ds_filt.isel(Time=~rect_mask)\n",
    "\n",
    "    # To filter the 'image' variable, you'll need to calculate the new start/stop indices. \n",
    "    # This can be tricky and resource-intensive because 'image' is a flat array \n",
    "    # and not indexed by 'Time'.\n",
    "    # For now, focus on the scalar data, which is filtered by 'Time'.\n",
    "    print(f\"Original particle count: {len(ds['Time'])}\")\n",
    "    print(f\"Filtered particle count: {len(ds_filt['Time'])}\")\n",
    "    mask = (ds_filt['Time'] <= l_mask)\n",
    "    liquid_particles = ds_filt.isel(Time =mask.values)\n",
    "    \n",
    "    \n",
    "    mask = (ds_filt['Time'] >= s_mask)\n",
    "    solid_particles = ds_filt.isel(Time =mask.values)\n",
    "    ##Assign phase labels\n",
    "    liquid_particles['phase'] = 0\n",
    "    solid_particles['phase'] = 1\n",
    "    n_liq = liquid_particles.dims['Time']\n",
    "    n_sol = solid_particles.dims['Time']\n",
    "    print(f\"Number of solid particles: {n_sol}\")\n",
    "    print(f\"Number of liquid particles: {n_liq}\")\n",
    "    # Re-index particle indices\n",
    "    end_index = start_index + n_liq\n",
    "    ds_sol = solid_particles.rename_dims({'Time':'particle_idx_seq'})\n",
    "    ds_liq = liquid_particles.rename_dims({'Time':'particle_idx_seq'})\n",
    "    ds_liq['particle_idx_seq'] = np.arange(start_index, end_index)\n",
    "    ds_sol['particle_idx_seq'] = np.arange(end_index, end_index + n_sol)\n",
    "\n",
    "    print(f\"Assigned particle_idx_seq from {start_index} to {end_index + n_sol -1}. \\n New start index for next call: {end_index + n_sol}\")\n",
    "\n",
    "    #concat_ds = xr.concat([ds_liq, ds_sol], dim='particle_idx_seq')\n",
    "    if start_index ==0:\n",
    "        return ds_liq, ds_sol, end_index + n_sol\n",
    "    return ds_liq, ds_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66aa838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/3328646582.py:8: UserWarning: Converting non-nanosecond precision timedelta values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  utc_times = origin + ds['probetime'].astype('timedelta64[s]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquid cutoff time: 2025-05-24T02:52:29.000000000\n",
      "Solid cutoff time: 2025-05-24T03:01:37.000000000\n"
     ]
    }
   ],
   "source": [
    "dsH['Time']= convert_time(dsH)\n",
    "rect_mask = (dsH['area']==dsH['perimeterarea']) & (dsH['diam'] > 100) & (dsH['arearatio'] < 0.1)\n",
    "rects = dsH.isel(Time=rect_mask)\n",
    "\n",
    "l,s = find_cutoffs(ds_env)\n",
    "solmask = (rects['Time'] >= s)\n",
    "solrect = rects.isel(Time=solmask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82a9049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/3328646582.py:8: UserWarning: Converting non-nanosecond precision timedelta values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  utc_times = origin + ds['probetime'].astype('timedelta64[s]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquid cutoff time: 2025-05-24T02:52:29.000000000\n",
      "Solid cutoff time: 2025-05-24T03:01:37.000000000\n",
      "Original particle count: 3754562\n",
      "Filtered particle count: 73166\n",
      "Number of solid particles: 3012\n",
      "Number of liquid particles: 1629\n",
      "Assigned particle_idx_seq from 0 to 4640. \n",
      " New start index for next call: 4641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/4228364844.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  n_liq = liquid_particles.dims['Time']\n",
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/4228364844.py:27: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  n_sol = solid_particles.dims['Time']\n",
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/3328646582.py:8: UserWarning: Converting non-nanosecond precision timedelta values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  utc_times = origin + ds['probetime'].astype('timedelta64[s]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquid cutoff time: 2025-05-24T02:52:29.000000000\n",
      "Solid cutoff time: 2025-05-24T03:01:37.000000000\n",
      "Original particle count: 3666455\n",
      "Filtered particle count: 62598\n",
      "Number of solid particles: 947\n",
      "Number of liquid particles: 1594\n",
      "Assigned particle_idx_seq from 4641 to 7181. \n",
      " New start index for next call: 7182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/4228364844.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  n_liq = liquid_particles.dims['Time']\n",
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/4228364844.py:27: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  n_sol = solid_particles.dims['Time']\n"
     ]
    }
   ],
   "source": [
    "##filter V and H datasets\n",
    "dsV['Time'] = convert_time(dsV)\n",
    "liq, sol, start_idx = filter_particles(dsV,ds_env)\n",
    "dsH['Time']  = convert_time(dsH)\n",
    "liqH,solH = filter_particles(dsH,ds_env, start_index=start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bd6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_particles = [liq, liqH]\n",
    "s_particles = [sol, solH]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699472c",
   "metadata": {},
   "source": [
    "## Standardized function to scale a particle to a 128x128 canvas and save the plot into specified output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239065dc",
   "metadata": {},
   "source": [
    "### Save images for all particles, or specify your start particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536e2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "# Make sure the output directory exists\n",
    "output_dir = 'particle_images_filtered'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "def plot_particle_standardized(ds, particle_index, target_size=128, max_fit=128, save=True, output_dir=output_dir):\n",
    "    \"\"\"\n",
    "    Produce a clean 128x128 grayscale image suitable for CNN input.\n",
    "    - No text overlay\n",
    "    - Returned array is float32 normalized to [0, 1]\n",
    "    - Saved PNG (if save=True) contains only the image pixels\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from skimage.transform import resize\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    pnumber = str(ds['particle_idx_seq'][particle_index].values)\n",
    "    # safety: ensure output dir exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # defensive indexing\n",
    "    try:\n",
    "        start_slice = int(ds['starty'].values[particle_index])\n",
    "        stop_slice = int(ds['stopy'].values[particle_index])\n",
    "        start_diode = int(ds['startx'].values[particle_index])\n",
    "        stop_diode = int(ds['stopx'].values[particle_index])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # load only the small image patch for this particle\n",
    "    cropped_image = ds['image'].values[start_slice:stop_slice, start_diode:stop_diode]\n",
    "\n",
    "    # ensure binary and small memory footprint\n",
    "    cropped_image = (cropped_image > 0).astype(np.uint8)\n",
    "\n",
    "    # trim empty rows/cols\n",
    "    rows_with_data = np.any(cropped_image == 1, axis=1)\n",
    "    cols_with_data = np.any(cropped_image == 1, axis=0)\n",
    "    if not np.any(rows_with_data) or not np.any(cols_with_data):\n",
    "        return None\n",
    "\n",
    "    cropped_image = cropped_image[rows_with_data][:, cols_with_data]\n",
    "    H_current, W_current = cropped_image.shape\n",
    "\n",
    "    # scale preserving aspect ratio so largest side == max_fit\n",
    "    max_dim = max(H_current, W_current)\n",
    "    if max_dim == 0:\n",
    "        return None\n",
    "    scale_factor = float(max_fit) / float(max_dim)\n",
    "\n",
    "    new_H = max(1, int(round(H_current * scale_factor)))\n",
    "    new_W = max(1, int(round(W_current * scale_factor)))\n",
    "\n",
    "    # nearest-neighbor resize to keep binary structure\n",
    "    resized_image = resize(\n",
    "        cropped_image,\n",
    "        (new_H, new_W),\n",
    "        order=0,\n",
    "        anti_aliasing=False,\n",
    "        preserve_range=True\n",
    "    )\n",
    "    resized_image = (resized_image > 0.5).astype(np.uint8)\n",
    "\n",
    "    # center on canvas\n",
    "    canvas = np.zeros((target_size, target_size), dtype=np.uint8)\n",
    "    pad_y = (target_size - new_H) // 2\n",
    "    pad_x = (target_size - new_W) // 2\n",
    "    canvas[pad_y:pad_y + new_H, pad_x:pad_x + new_W] = resized_image\n",
    "    \n",
    "    ##invert colors\n",
    "    canvas = 1 - canvas\n",
    "\n",
    "    # normalize to float32 [0,1] for CNN\n",
    "    canvas_f = canvas.astype(np.float32) / 255.0 if canvas.max() > 1 else canvas.astype(np.float32)\n",
    "\n",
    "    # save as 8-bit PNG without text/axes\n",
    "    if save:\n",
    "        # convert to 0-255 uint8 for disk\n",
    "        out_img = (canvas_f * 255).astype(np.uint8)\n",
    "        plt.imsave(f\"{output_dir}/particle_{pnumber}.png\", out_img, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    return canvas_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcb1ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/262451929.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"Processing dataset with {p_ds.dims['particle_idx_seq']} particles...\")\n",
      "/var/folders/bm/ggq_7b1n5g10y_2mdnxrjtc1fjxyx8/T/ipykernel_47937/262451929.py:8: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for particle_index in range(p_ds.dims['particle_idx_seq']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset with 1629 particles...\n",
      "Processing dataset with 1594 particles...\n",
      "Processing dataset with 3012 particles...\n",
      "Processing dataset with 947 particles...\n"
     ]
    }
   ],
   "source": [
    "liquid_dir = os.path.join(output_dir, 'liquid')\n",
    "os.makedirs(liquid_dir, exist_ok=True)\n",
    "solid_dir = os.path.join(output_dir, 'solid')\n",
    "os.makedirs(solid_dir, exist_ok=True)\n",
    "# Loop through all indices (or a subset for testing)\n",
    "def process_and_save_particles(p_ds, output_dir=output_dir):\n",
    "    print(f\"Processing dataset with {p_ds.dims['particle_idx_seq']} particles...\")\n",
    "    for particle_index in range(p_ds.dims['particle_idx_seq']):\n",
    "        plot_particle_standardized(p_ds, particle_index, output_dir=output_dir)\n",
    "\n",
    "for ds in l_particles:\n",
    "    process_and_save_particles(ds, output_dir=liquid_dir)\n",
    "\n",
    "for ds in s_particles:\n",
    "    process_and_save_particles(ds, output_dir=solid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "150f5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert subset ds to pandas dataframe\n",
    "particles_df = []\n",
    "for particle in l_particles:\n",
    "    df = particle[['particle_idx_seq','phase']].to_dataframe()\n",
    "    particles_df.append(df)\n",
    "for particles in s_particles:\n",
    "    df = particles[['particle_idx_seq','phase']].to_dataframe()\n",
    "    particles_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0fdbc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= pd.concat(particles_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(output_dir +'/particle_phases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f76e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
